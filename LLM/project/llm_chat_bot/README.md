## Running chatbot from local LLM model


### Steps to Run Application

[Application Run Guide](https://github.com/abcofdevops/aiops/blob/main/LLM/project/README.md)


##  How It Works

1. The script starts the chat and take your input.
2. Connects to the Ollama API running locally.
3. Generates an Answer.
4. Returns the Answer as output.
5. It keeps the chat open until you type exit or quit.
