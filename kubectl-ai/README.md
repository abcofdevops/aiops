# kubectl-ai

kubectl-ai is a LLM based AI tool generated by [GoogleCloudPlatform](https://github.com/GoogleCloudPlatform) to understansd user intent and convert that into kubernetes commands and moreover apply them to your kubernetes cluster. It makes kubernetes management more accessible and efficient.

> #### Official Repository: [GoogleCloudPlatform/kubectl-ai](https://github.com/GoogleCloudPlatform/kubectl-ai)

## Prerequisites
- kubernetes cluster is ready to use.
- kubectl is installed and configured.

## Installation
- Download the latest release: [releases page](https://github.com/GoogleCloudPlatform/kubectl-ai/releases/latest)

- Untar the release and add it to your local directory
    ```bash
    tar -xvzf *.tar.gz
    chmod a+x kubectl-ai
    sudo mv kubectl-ai /usr/local/bin/
    ```

## Running `kubectl-ai`
kubectl-ai support a variety of hosted and local LLM models

- Hosted Model
    - using Google AI Studio
        ```bash 
        export GEMINI_API_KEY=your_api_key
        kubectl-ai
        ```
    - Other Hosted LLM's
        - Different gemini model
            ```bash
            export GEMINI_API_KEY=your_api_key
            kubectl-ai --model gemini-2.5-pro-exp-03-25
            ```
        - OpenAI
            ```bash
            export OPENAI_API_KEY=your_openai_api_key
            kubectl-ai --llm-provider-openai --model=gpt-4.1
- Local Model
    - using gemma3 with `ollama`
        ```bash
        kubectl-ai --llm-provider ollama --model gemma3:12b-it-qat --enable-tool-use-shim


## Configuration
Use other models 

```bash
mkdir -p ~/.config/kubectl-ai/config.yaml

cat <<EOF > ~/.config/kubectl-ai/config.yaml
model:
llm-provider:
EOF
```

## Usage

```bash
kubectl-ai 

>>> create a deployment with 3 replicas for nginx in nginx namespace
```

